{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plot\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys, os, re\n",
    "\n",
    "# trying new vis package\n",
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make numpy values easier to read\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path=\"/home/clayton/science/CANlab/WAViMedEEG/PainStudyFiles/csv/\"\n",
    "train_filenames_glob = tf.io.gfile.glob(train_file_path+\"*.csv\")\n",
    "\n",
    "test_file_path=\"/home/clayton/science/CANlab/WAViMedEEG/PainStudyFiles/witheld/\"\n",
    "test_filenames_glob = tf.io.gfile.glob(test_file_path+\"*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to help us plot our results\n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "    plot.grid(False)\n",
    "    plot.xticks([])\n",
    "    plot.yticks([])\n",
    "\n",
    "    plot.imshow(img, cmap=plot.cm.binary)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plot.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "    100*np.max(predictions_array),\n",
    "    class_names[true_label]),\n",
    "    color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "    plot.grid(False)\n",
    "    plot.xticks([])\n",
    "    plot.yticks([])\n",
    "    thisplot = plot.bar(range(10), predictions_array, color=\"#777777\")\n",
    "    plot.ylim([0, 1])\n",
    "    predicted_label = lnp.argmax(predictions_array)\n",
    "\n",
    "    thisplot[predicted_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation of actual tensor dataset\n",
    "def get_dataset(file_pattern):\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        file_pattern,\n",
    "        batch_size = 64,\n",
    "        column_names=['group','C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13','C14','C15','C16','C17','C18','C19'],\n",
    "        column_defaults=None,\n",
    "        label_name='group',\n",
    "        select_columns=None,\n",
    "        field_delim=',',\n",
    "        use_quote_delim=False,\n",
    "        na_value='',\n",
    "        header=False,\n",
    "        num_epochs=5,\n",
    "        shuffle=True,\n",
    "        shuffle_buffer_size=128,\n",
    "        shuffle_seed=None,\n",
    "        prefetch_buffer_size=tf.data.experimental.AUTOTUNE,\n",
    "        num_parallel_reads=12,\n",
    "        sloppy=False,\n",
    "        num_rows_for_inference=50,\n",
    "        compression_type=\"\"\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare class names\n",
    "LABELS = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_dataset(train_filenames_glob)\n",
    "test_data = get_dataset(test_filenames_glob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_dim, hidden_units=[100]):\n",
    "    \"\"\"\n",
    "    Create a Keras model with layers\n",
    "\n",
    "    Args:\n",
    "        input_dim: (int) The shape of an item in a batch\n",
    "        labels_dim: (int) The shape of a label\n",
    "        hidden_units: [int] the layer sizes of the DNN (input layer first)\n",
    "        learning_rate: (float) the learning rate for the optimizer\n",
    "\n",
    "    Returns:\n",
    "        A Keras model\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.Input(shape=(input_dim,))\n",
    "    x = inputs\n",
    "\n",
    "    for units in hidden_units:\n",
    "        x = tf.keras.layers.Dense(units, activation='relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.compat.v1.data' has no attribute 'get_output_shapes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-0c377c5e907e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0minput_dimension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# [0] is the batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.compat.v1.data' has no attribute 'get_output_shapes'"
     ]
    }
   ],
   "source": [
    "input_shape, output_shape = tf.compat.v1.data.get_output_shapes(train_data)\n",
    "input_dimension = input_shape.dims[1] # [0] is the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_dimension' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-dee03c1d4137>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dimension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m model.compile(\n\u001b[1;32m      3\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_dimension' is not defined"
     ]
    }
   ],
   "source": [
    "model = get_model(input_dimension)\n",
    "model.compile(\n",
    "    loss = 'binary_crossentropy',\n",
    "    optimizer = 'adam',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "model.fit(train_data, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check accuracy on test_data set\n",
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "print('\\n\\nTest Loss {}, Test Accuracy {}'.format(test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#infer labels on a batch or a dataset of batches\n",
    "predictions = model.predict(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
